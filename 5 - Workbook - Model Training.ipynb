{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPANION WORKBOOK\n",
    "\n",
    "# Model Training\n",
    "\n",
    "To make the most out of this program, we strongly recommend you to:\n",
    "1. First practice writing and implementing all of the code from Coding Section of the online module.\n",
    "2. Then, freely experiment with and explore any interesting or confusing concepts. Simply insert new code cells and then use the help of Google and official documentation.\n",
    "3. Finally, tackle all of the exercises at the end. They will help you tie everything together and **learn in context.**\n",
    "\n",
    "#### <span style=\"color:#555\">MODULE CODE SANDBOX</span>\n",
    "\n",
    "Use this space to practice writing and implementing all of the code from Coding Section of the online module. Insert new code cells as needed, and feel free to write notes to yourself in Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Spending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0ec0c868f28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('analytical_base_table.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.tx_price\n",
    "X = df.drop('tx_price', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "print( len(X_train), len(X_test), len(y_train), len(y_test) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocessing & Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.121</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-1.740</td>\n",
       "      <td>-2.843</td>\n",
       "      <td>-2.692</td>\n",
       "      <td>-1.396</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.128</td>\n",
       "      <td>12.149</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>3.915</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.349</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.912</td>\n",
       "      <td>4.013</td>\n",
       "      <td>4.156</td>\n",
       "      <td>1.537</td>\n",
       "      <td>1.988</td>\n",
       "      <td>4.791</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.284</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beds   baths    sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 373.000 373.000 373.000   373.000   373.000      373.000    373.000   \n",
       "mean   -0.117  -0.081  -0.091    -0.032     0.011        0.091      0.141   \n",
       "std     0.959   0.989   1.002     1.034     0.988        1.004      0.996   \n",
       "min    -2.269  -1.697  -1.261    -0.366    -2.688       -0.841     -0.976   \n",
       "25%    -0.405  -0.622  -0.804    -0.325     0.372       -0.628     -0.753   \n",
       "50%    -0.405  -0.622  -0.387    -0.266     0.372       -0.287     -0.086   \n",
       "75%     0.527   0.452   0.306    -0.063     0.372        0.500      0.581   \n",
       "max     1.459   3.676   4.128    12.149     0.372        4.821      3.915   \n",
       "\n",
       "       nightlife   cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count    373.000 373.000   373.000             373.000      373.000   \n",
       "mean       0.057   0.109     0.132               0.048        0.108   \n",
       "std        1.034   1.078     1.121               1.013        1.019   \n",
       "min       -0.593  -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.474  -0.562    -0.565              -0.716       -0.657   \n",
       "50%       -0.356  -0.294    -0.259              -0.290       -0.230   \n",
       "75%        0.118   0.244     0.333               0.349        0.587   \n",
       "max        5.804   5.349     5.741               6.741        5.912   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count      373.000     373.000  373.000       373.000       373.000   \n",
       "mean         0.035       0.072   -0.101         0.010        -0.064   \n",
       "std          0.922       1.021    0.949         0.945         0.890   \n",
       "min         -0.876      -1.740   -2.843        -2.692        -1.396   \n",
       "25%         -0.543      -0.682   -0.678        -0.703        -0.652   \n",
       "50%         -0.265      -0.077    0.077         0.058        -0.243   \n",
       "75%          0.346       0.679    0.631         0.760         0.267   \n",
       "max          4.013       4.156    1.537         1.988         4.791   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  property_age  \\\n",
       "count    373.000        373.000      373.000      373.000       373.000   \n",
       "mean      -0.055         -0.036        0.121        0.050         0.013   \n",
       "std        0.908          1.043        0.895        1.068         0.972   \n",
       "min       -1.295         -2.790       -3.440       -0.319        -1.148   \n",
       "25%       -0.666         -0.765        0.427       -0.319        -0.912   \n",
       "50%       -0.246          0.248        0.427       -0.319        -0.158   \n",
       "75%        0.271          0.754        0.427       -0.319         0.691   \n",
       "max        5.375          1.767        2.360        3.129         3.284   \n",
       "\n",
       "       during_recession  school_score  exterior_walls_Brick  \\\n",
       "count           373.000       373.000               373.000   \n",
       "mean             -0.025         0.033                 0.066   \n",
       "std               0.987         1.011                 1.018   \n",
       "min              -0.601        -2.316                -0.749   \n",
       "25%              -0.601        -0.921                -0.749   \n",
       "50%              -0.601         0.009                -0.749   \n",
       "75%               1.662         0.939                 1.334   \n",
       "max               1.662         1.869                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                      373.000                     373.000   \n",
       "mean                         0.052                      -0.046   \n",
       "std                          1.150                       0.910   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count               373.000                 373.000               373.000   \n",
       "mean                 -0.027                  -0.005                -0.043   \n",
       "std                   0.951                   0.996                 0.890   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                             373.000              373.000       373.000   \n",
       "mean                               -0.025               -0.006        -0.003   \n",
       "std                                 0.988                0.991         0.996   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                   373.000       373.000     373.000             373.000   \n",
       "mean                      0.011        -0.004       0.028              -0.052   \n",
       "std                       0.998         0.998       1.051               0.853   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                      373.000   \n",
       "mean                                         0.112   \n",
       "std                                          1.013   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                      373.000  \n",
       "mean                        -0.112  \n",
       "std                          1.013  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new = (X_train - X_train.mean()) / X_train.std()\n",
    "\n",
    "X_train_new.describe()\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "X_train_new.describe()\n",
    "\n",
    "X_test_new = (X_test - X_train.mean()) / X_train.std()\n",
    "\n",
    "X_test_new.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipelines = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state=1234)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state=1234))\n",
    "}\n",
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state=123))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso hyperparameters\n",
    "lasso_hyperparameters = { \n",
    "    'lasso__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] \n",
    "}\n",
    "\n",
    "# Ridge hyperparameters\n",
    "ridge_hyperparameters = { \n",
    "    'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]  \n",
    "}\n",
    "\n",
    "enet_hyperparameters = { \n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],                        \n",
    "    'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]  \n",
    "}\n",
    "\n",
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'lasso' : lasso_hyperparameters,\n",
    "    'ridge' : ridge_hyperparameters,\n",
    "    'enet' : enet_hyperparameters\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(pipelines['lasso'], hyperparameters['lasso'], cv = 10, n_jobs=-1)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('lasso',\n",
       "                                        Lasso(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=1000,\n",
       "                                              normalize=False, positive=False,\n",
       "                                              precompute=False,\n",
       "                                              random_state=1234,\n",
       "                                              selection='cyclic', tol=0.0001,\n",
       "                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
       "                                          5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted\n",
      "ridge has been fitted\n",
      "enet has been fitted\n"
     ]
    }
   ],
   "source": [
    "fitted_models = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    print(name, 'has been fitted')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.3086275110508401\n",
      "ridge 0.3166111585985649\n",
      "enet 0.34287462866116075\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.4088862476281637\n",
      "MAE: 85035.54256465772\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pred = fitted_models['lasso'].predict(X_test)\n",
    "\n",
    "print('R^2:', r2_score(y_test, pred))\n",
    "print('MAE:', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#555\">EXERCISES</span>\n",
    "\n",
    "Complete each of the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.1 - Coding Section Checkpoint</span>\n",
    "\n",
    "Before moving on, it's imperative that you've been following along the online Coding Section of this module. Those are core to each module and often contain **mission-critical code**, which means that the following modules REQUIRE you to have run that code.\n",
    "\n",
    "#### A.) First, confirm that you've successfully separated the data into a training set and a test set.\n",
    "* How many observations are in the training set?\n",
    "* How many observations are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n",
      "373\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, display the Ridge regression pipeline object saved in the pipelines dictionary.\n",
    "* What steps are in the pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('ridge',\n",
      "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                       max_iter=None, normalize=False, random_state=1234,\n",
      "                       solver='auto', tol=0.001))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(pipelines['ridge'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=123, solver='auto', tol=0.001))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, display the <code>l1_ratio</code> hyperparameter values to try for your Elastic-Net algorithm.\n",
    "* **Tip:** Remember the naming convention within pipelines (need the named step first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.3, 0.5, 0.7, 0.9]\n"
     ]
    }
   ],
   "source": [
    "print( enet_hyperparameters['elasticnet__l1_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.2 - Sklearn's Standard Scaler</span>\n",
    "\n",
    "Whenever you preprocess your dataset, it's important to use the same **preprocessing parameters** on new data as you used on the training set. So if you standardize your dataset, you must also standardize the test set with the same means and standard deviations from the training set.\n",
    "\n",
    "#### A.) First, display the standardization parameters for the <code>beds</code> feature in the training set (<code>X_train</code>).\n",
    "* You'll need the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.434228187919463\n",
      "1.0729140858452646\n"
     ]
    }
   ],
   "source": [
    "print(X_train.beds.mean())\n",
    "print(X_train.beds.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0729140858452646\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TRAINING set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689    1.459\n",
      "1531    0.527\n",
      "668    -0.405\n",
      "1740    1.459\n",
      "117    -1.337\n",
      "Name: beds, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "a = (X_train.beds.head() - X_train.beds.mean())/X_train.beds.std()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "1689    1.459\n",
    "1531    0.527\n",
    "668    -0.405\n",
    "1740    1.459\n",
    "117    -1.337\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TEST set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266   -1.337\n",
      "790   -0.405\n",
      "222   -1.337\n",
      "220   -1.337\n",
      "920   -0.405\n",
      "Name: beds, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "b = (X_test.beds.head() - X_train.beds.mean())/X_train.beds.std()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "266   -1.337\n",
    "790   -0.405\n",
    "222   -1.337\n",
    "220   -1.337\n",
    "920   -0.405\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Scikit-Learn's <code>StandardScaler()</code> class allows you to save those preprocessing parameters learned from the training set.\n",
    "1. First, initialize and instance of the scaler class.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "scaler = StandardScaler()\n",
    "</pre>\n",
    "\n",
    "2. Then, call the <code>.fit()</code> while passing in the **entire** training set (all of the features, not just beds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.) Now you can display the preprocessing parameters directly from the <code>scaler</code> object.\n",
    "* It will save the means from all features as an array in <code>.mean_</code>.\n",
    "* It will save the standard deviations from all features as an array in <code>.scale_</code>.\n",
    "* **Tip:** The <code>beds</code> feature should be the first one.\n",
    "* Check for yourself that the preprocessing parameters are the same as the ones you found in part (A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.43422819e+00 2.57919463e+00 2.32278523e+03 1.27466597e+04\n",
      " 8.78523490e-01 3.94959732e+01 4.38859060e+00 5.00469799e+00\n",
      " 5.18590604e+00 3.95610738e+01 3.36174497e+00 2.29093960e+01\n",
      " 1.57704698e+01 3.85087248e+01 6.94711409e+01 6.50127517e+01\n",
      " 4.64265772e+02 1.39610067e+02 6.51006711e+00 2.77919463e+00\n",
      " 9.26174497e-02 2.43436242e+01 2.65771812e-01 1.79402685e+01\n",
      " 3.59731544e-01 2.41610738e-02 5.90604027e-02 6.57718121e-02\n",
      " 1.19463087e-01 3.75838926e-02 2.68456376e-01 6.57718121e-02\n",
      " 7.31543624e-02 6.43624161e-01 1.89261745e-01 6.04026846e-02\n",
      " 3.35570470e-02 4.19463087e-01 5.80536913e-01]\n",
      "[1.07255399e+00 9.30163814e-01 1.29666633e+03 3.47938634e+04\n",
      " 3.26680222e-01 4.69700924e+01 4.49683006e+00 8.43916116e+00\n",
      " 7.44020928e+00 5.23172880e+01 4.69213389e+00 2.57158292e+01\n",
      " 1.79932407e+01 6.61300258e+00 1.98584126e+01 1.70868048e+01\n",
      " 2.27173547e+02 7.14869043e+01 1.97456120e+00 5.17061284e-01\n",
      " 2.89895598e-01 2.12019067e+01 4.41743315e-01 6.44989381e+00\n",
      " 4.79921619e-01 1.53549068e-01 2.35737718e-01 2.47882797e-01\n",
      " 3.24332635e-01 1.90187654e-01 4.43156350e-01 2.47882797e-01\n",
      " 2.60389711e-01 4.78928074e-01 3.91716399e-01 2.38231401e-01\n",
      " 1.80086012e-01 4.93471180e-01 4.93471180e-01]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0725539871320342\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.) Next, use the <code>scaler</code> object to <code>.transform()</code> your test set and save it as <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(373, 39)\n"
     ]
    }
   ],
   "source": [
    "X_test_new = scaler.transform(X_test)\n",
    "print(type(X_test_new))\n",
    "print(X_test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you use <code>scaler</code> to transform a dataset, it returns a NumPy array and NOT a Pandas DataFrame.\n",
    "\n",
    "#### G.) Confirm this for yourself. Display the class and shape of <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'numpy.ndarray'&gt;\n",
    "(373, 39)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H.) Finally, display the first 5 transformed values for the <code>beds</code> feature.\n",
    "* Because <code>X_test_new</code> is a NumPy array, you won't be able to just call <code>.beds</code> like with Pandas DataFrames. If you try that, you'll get the error:\n",
    "\n",
    "<pre>\n",
    "<span style=\"color:crimson\">AttributeError:</span> 'numpy.ndarray' object has no attribute 'beds'\n",
    "</pre>\n",
    "\n",
    "* Instead, you'll need to index the NumPy array to get the **first 5 rows** from the **first column**. (This is just meant as a refresher and a bit of practice.)\n",
    "* Confirm that the values are the same as the ones you found in part (C) manually. Note that the rounding/precision may be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.33720839, -0.40485439, -1.33720839, -1.33720839, -0.40485439])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new[0:5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.3 - Tree Pipelines</span>\n",
    "\n",
    "In the Coding Section, we created a pipeline dictionary with model pipelines for Lasso, Ridge, and Elastic-Net regressions. In this exercise, let's add pipelines for tree ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) Add pipelines for <code style=\"color:SteelBlue\">RandomForestRegressor</code> and <code style=\"color:SteelBlue\">GradientBoostingRegressor</code> to your pipeline dictionary.\n",
    "* Name them <code style=\"color:crimson\">'rf'</code> for random forest and <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "* Both pipelines should standardize the data first.\n",
    "* For both, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=1234))\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Just as a quick sanity check, display the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso': Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('lasso',\n",
      "                 Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                       max_iter=1000, normalize=False, positive=False,\n",
      "                       precompute=False, random_state=1234, selection='cyclic',\n",
      "                       tol=0.0001, warm_start=False))],\n",
      "         verbose=False), 'ridge': Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('ridge',\n",
      "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                       max_iter=None, normalize=False, random_state=1234,\n",
      "                       solver='auto', tol=0.001))],\n",
      "         verbose=False), 'enet': Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('elasticnet',\n",
      "                 ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                            l1_ratio=0.5, max_iter=1000, normalize=False,\n",
      "                            positive=False, precompute=False, random_state=123,\n",
      "                            selection='cyclic', tol=0.0001,\n",
      "                            warm_start=False))],\n",
      "         verbose=False), 'rf': Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
      "                                       criterion='mse', max_depth=None,\n",
      "                                       max_features='auto', max_leaf_nodes=None,\n",
      "                                       max_samples=None,\n",
      "                                       min_impurity_decrease=0.0,\n",
      "                                       min_impurity_split=None,\n",
      "                                       min_samples_leaf=1, min_samples_split=2,\n",
      "                                       min_weight_fraction_leaf=0.0,\n",
      "                                       n_estimators=100, n_jobs=None,\n",
      "                                       oob_score=False, random_state=1234,\n",
      "                                       verbose=0, warm_start=False))],\n",
      "         verbose=False), 'gb': Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
      "                                           criterion='friedman_mse', init=None,\n",
      "                                           learning_rate=0.1, loss='ls',\n",
      "                                           max_depth=3, max_features=None,\n",
      "                                           max_leaf_nodes=None,\n",
      "                                           min_impurity_decrease=0.0,\n",
      "                                           min_impurity_split=None,\n",
      "                                           min_samples_leaf=1,\n",
      "                                           min_samples_split=2,\n",
      "                                           min_weight_fraction_leaf=0.0,\n",
      "                                           n_estimators=100,\n",
      "                                           n_iter_no_change=None,\n",
      "                                           presort='deprecated',\n",
      "                                           random_state=1234, subsample=1.0,\n",
      "                                           tol=0.0001, validation_fraction=0.1,\n",
      "                                           verbose=0, warm_start=False))],\n",
      "         verbose=False)}\n"
     ]
    }
   ],
   "source": [
    "print(pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) As another quick sanity check, display the class for the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pipelines['rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's check that all of the model pipelines are of the correct type. For each item in your <code>pipelines</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for key,value in pipelines.items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "ridge &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "enet &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "rf &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "gb &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.4 - Hyperparameter Grids</span>\n",
    "\n",
    "In the Coding Section, we declared hyperparameter grids for our regularized regression algorithms: Lasso, Ridge, and Elastic-Net. Next, let's do the same for our tree ensembles.\n",
    "\n",
    "\n",
    "#### Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "The first one we'll tune is <code style=\"color:steelblue; font-weight:bold\">n_estimators</code>.\n",
    "* This is the number of decision trees to include in the random forest.\n",
    "* Usually, more is better.\n",
    "* The default value is 10, which is usually too few.\n",
    "* Let's try 100 and 200.\n",
    "\n",
    "The second one we'll tune is <code style=\"color:steelblue; font-weight:bold\">max_features</code>.\n",
    "* This controls the number of features each tree is allowed to choose from.\n",
    "* It's what allows your random forest to perform feature selection.\n",
    "* The default value is <code style=\"color:crimson\">'auto'</code>, which sets <code style=\"color:steelblue\">max_features = n_features</code>.\n",
    "* Let's also try <code style=\"color:crimson\">'sqrt'</code>, which sets <code style=\"color:steelblue\">max_features = sqrt(n_features)</code>\n",
    "* And <code style=\"color:crimson\">0.33</code>, which sets <code style=\"color:steelblue\">max_features = 0.33 * n_features</code>\n",
    "\n",
    "#### A.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">RandomForestRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">rf_hyperparameters</code>\n",
    "\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__max_features'</span>: ['auto', 'sqrt', 0.33]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyperparameters = {\n",
    "    'randomforestregressor__n_estimators': [100,200],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "#### B.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">GradientBoostingRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">gb_hyperparameters</code>.\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__learning_rate'</span>: [0.05, 0.1, 0.2]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__max_depth'</span>: [1, 3, 5]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_hyperparameters = {\n",
    "    'gradientboostingregressor__n_estimators': [100,200],\n",
    "    'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth': [1,3,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our hyperparameters declared, let's store them in a dictionary for ease of access.\n",
    "\n",
    "#### C.) Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary.\n",
    "* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "    * If you forgot what those keys were, you can insert a new code cell and call <code style=\"color:steelblue\">pipelines.keys()</code> for a reminder.\n",
    "* Set the values to the corresponding **hyperparameter grids** we've been declaring throughout this module.\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'rf'</span> : rf_hyperparameters</code>\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'lasso'</span> : lasso_hyperparameters</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso': {'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]}, 'ridge': {'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]}, 'enet': {'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]}, 'rf': {'randomforestregressor__n_estimators': [100, 200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]}, 'gb': {'gradientboostingregressor__n_estimators': [100, 200], 'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2], 'gradientboostingregressor__max_depth': [1, 3, 5]}}\n"
     ]
    }
   ],
   "source": [
    "hyperparameters['rf'] = rf_hyperparameters\n",
    "hyperparameters['gb'] = gb_hyperparameters\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, run this code to check that <code style=\"color:steelblue\">hyperparameters</code> is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "enet was found in hyperparameters, and it is a grid.\n",
    "gb was found in hyperparameters, and it is a grid.\n",
    "ridge was found in hyperparameters, and it is a grid.\n",
    "rf was found in hyperparameters, and it is a grid.\n",
    "lasso was found in hyperparameters, and it is a grid.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.5 - Model Dictionaries</span>\n",
    "\n",
    "Similar to how we created dictionaries for our pipelines and hyperparameter grids, we can do the same for our fitted models. Obviously, there are other valid ways to organize your code and models, but this is a simple and practical way that does the job. By the end of the script, you'll have various dictionary objects that can each be accessed by the same consistent keys.\n",
    "\n",
    "#### A.) Create a dictionary of models named <code style=\"color:SteelBlue\">fitted_models</code> to store models that have been tuned using cross-validation.\n",
    "* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n",
    "* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n",
    "* **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted\n",
      "ridge has been fitted\n",
      "enet has been fitted\n",
      "rf has been fitted\n",
      "gb has been fitted\n"
     ]
    }
   ],
   "source": [
    "fitted_models = {}\n",
    "    \n",
    "for name,pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    fitted_models[name] = model\n",
    "    print(name, 'has been fitted')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Check that the models are of the correct type. For each item in your <code>fitted_models</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "ridge &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "enet &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "rf &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "gb &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, run this code to check that the models have been fitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso has been fitted.\n",
    "ridge has been fitted.\n",
    "enet has been fitted.\n",
    "rf has been fitted.\n",
    "gb has been fitted.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.6 - Model Selection</span>\n",
    "\n",
    "In the Coding Section, we displayed performance metrics for a sample Lasso regression model. Now, let's do the same thing for all of our models, including our tree ensembles and then pick the final winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) First, display the cross-validated training performance for each model in <code style=\"color:SteelBlue\">fitted_models</code> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.3086275110508401\n",
      "ridge 0.3166111585985649\n",
      "enet 0.34287462866116075\n",
      "rf 0.48049323652282167\n",
      "gb 0.4875374794772805\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso 0.30862751105084013\n",
    "ridge 0.3166111585985649\n",
    "enet 0.34285741369864786\n",
    "rf 0.4801823564169308\n",
    "gb 0.48778099198016756\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, use a <code style=\"color:SteelBlue\">for</code> loop, print the performance of each model in <code style=\"color:SteelBlue\">fitted_models</code> on the test set.\n",
    "* Print both <code style=\"color:SteelBlue\">r2_score</code> and <code style=\"color:SteelBlue\">mean_absolute_error</code>.\n",
    "* Those functions each take two arguments:\n",
    "    * The actual values for your target variable (<code style=\"color:SteelBlue\">y_test</code>)\n",
    "    * Predicted values for your target variable\n",
    "* Label the output with the name of the algorithm. For example:\n",
    "\n",
    "<pre style=\"color:crimson\">\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "-------\n",
      "R^2: 0.4088862476281637\n",
      "MAE: 85035.54256465772\n",
      "ridge\n",
      "-------\n",
      "R^2: 0.4093396476329718\n",
      "MAE: 84978.03564808935\n",
      "enet\n",
      "-------\n",
      "R^2: 0.4052451373126301\n",
      "MAE: 86298.63725254669\n",
      "rf\n",
      "-------\n",
      "R^2: 0.573903233679242\n",
      "MAE: 68833.96790884719\n",
      "gb\n",
      "-------\n",
      "R^2: 0.5423930641721175\n",
      "MAE: 70556.8746998556\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print('-------')\n",
    "    print('R^2:', r2_score(y_test, pred))\n",
    "    print('MAE:', mean_absolute_error(y_test, pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "\n",
    "<pre>\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.4088862476281637\n",
    "MAE: 85035.54256465772\n",
    "\n",
    "ridge\n",
    "--------\n",
    "R^2: 0.4093396476329718\n",
    "MAE: 84978.03564808934\n",
    "\n",
    "enet\n",
    "--------\n",
    "R^2: 0.4038573361696519\n",
    "MAE: 86529.0068234889\n",
    "\n",
    "rf\n",
    "--------\n",
    "R^2: 0.5712128842598444\n",
    "MAE: 67885.87587131368\n",
    "\n",
    "gb\n",
    "--------\n",
    "R^2: 0.5270040007880257\n",
    "MAE: 71245.11216404787\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, ask yourself these questions to pick the winning model:\n",
    "* Which model had the highest $R^2$ on the test set?\n",
    "* Which model had the lowest mean absolute error?\n",
    "* Are these two models the same one?\n",
    "* Did it also have the best holdout $R^2$ score from cross-validation?\n",
    "* Does it satisfy our project's win condition? (**Tip:** In the event of ambiguous results based on the previous questions, THIS should be your final deciding factor on whether a model is \"good enough.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, plot the performance of the winning model on the test set.\n",
    "* Plot a scatterplot with predicted transaction price on the x-axis and actual transaction price on the y-axis.\n",
    "* This last visual check is a nice way to confirm our model's performance.\n",
    "* Are the points scattered around the 45 degree diagonal (what does the 45 degree diagonal line represent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc8b68a8390>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD3CAYAAADyvkg2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2df3QU9b3337O7YZckmyy0mpBLDQkmPEEKPpgTioQ8va2I0QNa9Baxp733sZUq2FYL3oRYSBBEqIXTWzgWvL29PceWx/oDLVyNloI0JGLg8RQseWJQgdhLSLQCIVmyye7OPH+EWXcn851fO7M7u/t5ndNTmXxn5vud2fl+vt/PT04QBAEEQRAEAcCR7A4QBEEQ9oGEAkEQBBGBhAJBEAQRgYQCQRAEEYGEAkEQBBHBlewOxAPP8wiH09t5yunk0n6MStD4M3v8AD0DK8afleVk/i2lhUI4LODSpSvJ7oal+HzZaT9GJWj8mT1+gJ6BFeO/5hov82+kPiIIgiAikFAgCIIgIqiqj4LBIOrr63Hu3Dk4HA5s2LABLpcL9fX14DgOZWVlaGxshMPhwI4dO3Do0CG4XC40NDRg5syZ6O7ujrstQRAEkRhUZ9w///nPCIVCeP7557Fy5Ur8/Oc/x1NPPYVHHnkEu3fvhiAIOHDgADo6OnD06FG8+OKL2LZtG9avXw8AcbclCIIgEoeqUCgpKUE4HAbP8xgcHITL5UJHRweqqqoAADU1NXj77bfx7rvvorq6GhzHoaioCOFwGBcuXIi7LUEQBJE4VNVH2dnZOHfuHGpra3Hx4kXs3LkTx44dA8dxAICcnBwMDAxgcHAQPp8vcp54XBCEuNoq4XRy8Pmy9Y86hXA6HWk/RiVo/Kk7/r0nerB1/ymc7w9gUr4HqxaUY/GsIt3XSeVnYAaJHr+qUPjNb36D6upqrFq1CufPn8c///M/IxgMRv7u9/uRl5eH3Nxc+P3+mONerzfGJmCkrRLkkpr+0PhTc/zNnX3Y9McPEAjxAICe/gAef/Uk/FeGUVtRoOtaqfoMzMJ2Lql5eXnwekcvkJ+fj1AohOnTp6O9vR0A0NLSgsrKSsyePRutra3geR49PT3geR4TJ06Muy1BEMmjubMPi55tR9XWFix6th3NnX2aznvm8NmIQBAJhHg8c/isBb0kzIRTq6fg9/vR0NCATz/9FMFgEN/5zncwY8YMrF27FsFgEKWlpdi4cSOcTie2b9+OlpYW8DyPNWvWoLKyEmfOnIm7LYtgMJz2KwhaJdH4kzV+6WofADwuBxpuLVNd7VdtbYHcxMIBOLqqRlc/6DeQ2J2CqlCwMyQU0h8af/LGv+jZdvQODI85Xuh1Y9/yOZadK4V+AzZTHxEEkZn0yUzqSsejWTF/Cjyu2OnF43JgxfwpZnSNsJCUzn1EEIR1FHjdsqv9Aq9b9VxRvfTM4bPoGxhGgdeNFfOn6DYyE4mHhAJBELKsmD9F1qagdbVfW1FAQiAFIaFAEIQstNrPTEgoEATBhFb7yWfviR48/WZXwgQzCQWCIAib0tzZh037P0AgOKrC6x0YxqY/fgAAlgkG8j4iCIKwKc8cPhsRCCJWBwGSUCAIgrApLPff3oFh3VHmWiGhQBAEYVOU3H8FfK5OMlMwkE2BIAjb0dzZF/F6mpTvwYPzilPC4B3dbzOMwivmT4mxKcghqpPMej4kFAiCsBVyGVatNq7K9UHv5C7ttxlG4dqKAuRkuyPeR6ycRFqizLVC6iOCIGxFsjOsipN779VJWKuKxqp+L55VhH3L5+DoqhoUMtRJWqLMtUJCgSAIWxFPziUzMDq5J6LficgpRUKBIAhbwVr1mrkaVsLo5J6IftdWFKDh1jIUet3gMJp1Vksqcz2QTYEgCFsRb86leDGaCDBR/bY6ypyEAkEQtkKac0mv95EeI7FcW6OTe7rkiqIiOzaHCozQ+DN5/IC+Z6CnWpxSW8A+k3uii+zQToEgiLRByUgsndSV2u5bPiflVvhmQYZmgiDSBj1G4mR7OdkV2ikQBGEIUR/fOzAMBwfwwqg3TDJVLXqMxPFUlktnSCgQRJphZqoF1rWk+nj+qmUyEamdldBjJE62l5NdIaFAEGmEmakWlK4lp48XMTsXjx70eACli7eQ2ZBQIIg0Qo+hFVDeVShdS03vnky9vB4/fqosNxYSCgSRRigZT6UCYF7pBLzW8QlzV6F0LZY+XkROL292BlHCGsj7iCDSCJaRNM/jGpPk7eUTvYo5fvI88mvGPI9LNgePiJxe3miSOSLxkFAgiDSClTBNEASmDUCKuENgxbX2B0IAEMnBAwAObvRvrFw8RpLMNXf2YdGz7Shf+4YlFcYIeVTVR3v27MErr7wCABgeHkZnZyeee+45PPnkk3A6naiursbDDz8MnufR1NSErq4ujBs3Dhs3bkRxcTGOHz8eV1uCILTDMp42vt6l+RribmNgOMxss+mPH6Dh1jLsWz5H0zX1xgToMZgnQi2VSaovVaGwZMkSLFmyBACwfv163H333WhsbMT27dvxpS99CcuXL0dHRwfOnTuHkZER/P73v8fx48exefNm/PKXv4y77Q033GD5QyCIdELOeCrGE6gRrfpRshvo9TDSGxOg1WBuRWEbKYm4h53QbGj+61//ig8//BCrVq3Cb37zG1x33XUAgOrqahw5cgSffvop5s+fDwC48cYbcfLkSQwODmJkZCSutkpCwenk4PNlGxt5iuB0OtJ+jErQ+M0Z/2MLp+HxP5yMKevoyXJgyf/8Bxzq+hTn+wOYlO/BqgXlWDyriHlONH0Dw5r7xrr/YwunyV5DaWcR3X5nW7es8NjZ1o1lc0s09U0N1j2amruQk+2OPC+rSPQ3oFko7Nq1CytXrsTg4CByc3Mjx3NycvC3v/1tzHGn02lKWyXCYSHtk4VlekI0Gr85468p9qFhQZmsCuTR+bGTp3g/8Zym5q5IcFo0BV63Yt+kKpc7pl+LttMXY+5fU+yTvYbSziK6/fn+gOy9z/cHTPvdsO7BC0D9nr/Cf2XY0h2DLRPiXb58GadPn8ZXvvIVDA4Owu/3R/7m9/uRl5eHQCAQc5zneeTm5sbdliAIczDiky+21xv5K6dyea3jE80FYbRGGyciVYWSGi3IC0kL1LMKTd5Hx44dw8033wwAyM3NRVZWFj7++GMIgoDW1lZUVlZi9uzZaGlpAQAcP34c5eXlprQlCCK5GKn2FW+9Yq33TER5SrVrpVsCPU07hTNnzmDy5MmRf69fvx6rV69GOBxGdXU1Zs2ahS9/+ctoa2vDvffeC0EQsGnTJlPaEgSRfPTuMoxkIJXz8Nm3fI6i+iQRqSpqKwrwswMf4jLDGyvdEuhRkR2bQzp1Gn8qjn/Rs+2yKhcxi6p0EgfkVVQNt5Zh2dySpD+D5s4+PNHchZBktsxycFh7W3la2RQoeI0gCNNhqXXmlU6QjWzeevAjWXXT1oMfJbDXbGorCrCudhry3M7IsXyPy3KBkAwo9xFBEKbDUuuwbA2saOv+QAh7T/SgpthneZ/VyJTkeaQ+sjmpqj4wCxp/eo2/amsL9E44vvEu7F9xsyX9SQVs6ZJKEETySYdUC163U9Zg63FyCITlxcWloZDV3SKiIKFAECmA2akWkiVgOI6TPe7OciIQpsnfDpBQIAgZ7LYq11s8R4lk5vK5HJCf+C8HQsj3uCIZWKOZkJ1laZ+IWMj7iCAk2DH3vxG/fxbxBpZpQUx7XbW1JSbtNcunv8DrxqqvTUWWI3YnkeXg8JPbK0zrF6EOCQWCkJCISVMvSpOpXswUMHIoCVWlCOTaigKsva08Jop57W3lliecI2Ih9RFBSLB60jSC1lxAWrA6XxBLqP7swIfIHudCIMTDwY0mlCuUqOYyxe3TztBOgSAkmLkqNwsj+YdYWJ0viCU8Lw+HI8KIF2J3CIR9oJ0CQUgwc1VuJmatoq3OF6SUVTQaMWKZhIK9oOA1m5NuwUt6Sdb47eJ9lIrvX+rdpAWpGimaVHwGZkLBawRhA+yo27aLoFJDbicyFAzLupuKpHuJy1SChAJBpACpVidYKlSbO/uw7vUuxXOMxl0Q5kKGZoJIAezoJquH2oqCmAyjLNKtYE0qQkKBIFIAO7rJ6mX1168f4/UkxSwPL1bwHKEOqY+IlCdVdO3xYDS2wE7PJtrWIDcWszy8Uk3VZjdIKBApTaZMAEbcZPU8m0QJj2hbg1X3NDNPVCZC6iMipWFNAOte70ortYGR4DWtdohk5XqqrSjAvuVzsP72aQCARpPeWTqo2pIJ7RSIlEbpQ0/0rsHq1bZeN1mtk2MyV9ZW7PSsTuOR7pBQIGyP0mSrFj2bypNbvGidHONZWccrCNV2M0aubdeI9FSB1EeErdl7okdRtSGXx0dKItQG8biMWuUpozXHkdFcT3Jqpw1vnMLXd7RpHgvr3Yjv2YhKy8w8UZkI7RQIW7N1/ylF1YaaRwuQGLWB0dW2lTsMrTmOjK6s5QRhkBcQvFpuU8tYWLsZB4e4VFp2jEhPFUgoELbmfH9A9nj0ZCtOAHI5dxKlNjCqx7Zan69lcjSaIE/LDkxtLCyBxMqbRMZi6yGhQNiaSfke9MgIBrnJ1ursn0oYXW3bxVPGyMpaazZUpbGw3hlr50fGYuvRJBR27dqFgwcPIhgMYtmyZaiqqkJ9fT04jkNZWRkaGxvhcDiwY8cOHDp0CC6XCw0NDZg5cya6u7vjbktkLqsWlOPxV09qnmyTpTYwKpD07jDsFIwmJwjl4LjRfrP6yXpnidz12em5JhtnU1NTk1KD9vZ2NDc34z//8z+xaNEiHD58GHv27MFDDz2EH/3oR3jrrbcQDocRCATwwgsvYPfu3Zg3bx7q6uqwdOlS1NfXx9V26tSpzL7xvIBAIGj2M7EVHk9W2o9RiVlTJmKC24HO3kH4R8Io9Lrx469NteUHW3ZNLu67aTIeuLkY9900GWXX5Kqe8/HFK+jsGxxzfGHFNagu/ULM+xfVY5euZhsdHAnjyJmLmJTv1nQvsym7JheT8t2Rd5PvcSEc5iEVEQKgu5/Sa1v53u32XKVYMQfk5LB3XKo7hdbWVpSXl2PlypUYHBzEv/7rv+KFF15AVVUVAKCmpgZtbW0oKSlBdXU1OI5DUVERwuEwLly4gI6OjrjaLliwwIxnQKQw6Ww0bDt9UfPxRMQT6F0xy2VDbWruAi+p0mKkn+K1ra6nQBHQsagKhYsXL6Knpwc7d+7Ef//3f+Ohhx6CIAjgOA4AkJOTg4GBAQwODsLn80XOE4/H21YJp5ODz5etf9QphNPpSPsxKpHu41eyKfh82THjV2sbL3tP9GDT/g8QCEZ5Qu3/ADnZbiyeVaTpGsvmlqCRkSLbaD+t/g1Y/VzjJdHfgKpQ8Pl8KC0txbhx41BaWgq3243e3t7I3/1+P/Ly8pCbmwu/3x9z3Ov1xtgEjLRVIhwW0r4iE1WdSu/xK9kULl26EjN+tbbx8vSbXRGBIBII8nj6zS7UFPsYZ43F7H5a/Ruw+rnGS6Irr6lacW+66SYcPnwYgiCgr68PQ0NDmDt3Ltrb2wEALS0tqKysxOzZs9Ha2gqe59HT0wOe5zFx4kRMnz49rrYEkc5oDTDT21Yr0YFzLE8ivZ5Qav20W1prK55rKqO6U/jHf/xHHDt2DPfccw8EQcC6deswefJkrF27Ftu2bUNpaSkWLlwIp9OJyspKLF26FDzPY926dQCAurq6uNoSRDqjx2vJbJdbrbWU9bqBKvXTjulAkunKbEc4QRAE9Wb2JBgM22J7ZyXprj5Rg8Y/On4rXCYXPduuGmfgcTlMTRHBumeh1419y+fInkO/gcSqjyh4jSBsjlWrazW1kJhqQszfZIZgsEuwHsGGIsMIwuZYVZ+ZpRbKczvhcTkibqVm1lcwmnyPSBy0UyAyilSMXLVqdc1KzcFxHAKhcEzbQIhHU/Ooq6mR5yU+dyvLcBrtUyr9FhIBCQUiYzCqhkn25GFV0RiWgZUVZ8ALMKS2UjJoFyZpMrajwdsukFAgMgYjkat2mDzmlU7Ayyd6Y46ZtbqWixZXSkNuJNJX7rkDysZlq6EoZjZkUyAyBiNqGKv0+VrZe6IHr3V8Mub4HTdcOya9hFm+/2qFi/SqrexoXLZjn+wC7RSIjMGIGkbP5GGFmkmuyBAA7H//U7Sdvoi+gWHkeVzwD4cQkhiGAWO7GfEcuRxGgH61lR1rJtuxT3aBdgpExmAkclWrt4xcaUozPHZYRYYuD4cj9+oPfC4QROLdzdRWFKCpdpopkb52jBi2Y5/sAgkFImMwUrtX6+RhlZppUr7H8LnxqkLMqnVsx5rJduyTXaCIZptD0ZzJH78WtVDV1hawPqQ8txMDw2F4XBwCIQECRgPDvjGzEPW3lCveu6X70pgiQ1pJpiHXTOzwG0gmFNFMEDZDSz0HpdKUl68Wsh+K0vHwAiIeRUqCYfGsIvivDMcIpaFgGP1XC8KwIFUIYRQSCgRhAlpLU0p55b1e1d2CXCEb6b2yHBzGZzkwMBxOWiBWsuM5CHMgoUCoQh97LErPYx0j8IuFnHePGnbM6mmHeA7CHEgoEIrQxx6L2vPQKxQcnLF+2K1EKQWDpQ8kFAhF6GOPhfU8th78CLUVBchzOyM2BC18Y2YhAPXdmN13ayx7SvRxu4+BGIWEAqFIsiI/7TqBsMbdHwhh859OYcH/uGZMSgoWd88a9T5S2n0sm1uSErs1ByevChN3QqkwBmIUilMgFElGqmOrAsHMQGncL5/oxf73P9V0nUKvO2JgVotxSHaqDS2wbCPi8VQYAzEKCQVCkUREfkrz9mw9+JHhCcTq+r9q49aqOppXOiHy36zdR+/AMP7Xzw6ZVjvZSgoZwlI8rjRGO9RpJj6HhAKhiNWRn3K7ApYPvtokmIgdhmg3iJfXOj6J9Etp99HDSHMBAF4T+mEWaosHpTHaaSdIkE2B0ICVni6stMpyqKms4jGKy9kwxGtK7Rqrv34908so3+PCcIhXHVN0v1bMn4INb5xCUKd/KscZdF2yADU3WbU4jkx2XrAbJBSIpKJVBaJFZWXUKC5nBH2iuQscx0Umaqlh9MS5ftkaB6u+NhWAck0Cab9qKwrwswMfIqjDawkALqtENScapcVDtNBIBXVYJkPqIyKpKK3+8z0uXSoro0ZxuR1GSMCYlXu0XaP+lnI8cfs0WbWauPpXI7pfAzoFgvT8VKC2ogD7ls9h2h9SbTzpCu0UiKSyYv4UpipmfJYT//fxWzQnA2PVHDa6w1Brq7QyVjOKS/ullDvJxSFm1yJ3fiph9D0RiYF2CkRSUVr961UnGDWK61mham2r1Pc8t3NMv1jVziZkZ2Fd7TSsva08bdI8Z1raaqs94syGdgpE0ik0sQqWEaO43Mo13tU5a+Wf53biwMPzZPsNjDXULptbEtkppdOkabc0HVaRikF7JBSIpJNsdQJrQpY7pvVDZnnbXB4OY9Gz7bLXMnuiTERUuF0jz+1CKqaJ0SQU7rrrLni9o0UZJk+ejKVLl+LJJ5+E0+lEdXU1Hn74YfA8j6amJnR1dWHcuHHYuHEjiouLcfz48bjaEumPkjvj3hM9ePrNLssnHdaELD2mdRJU8rZJxGoxESvUVFwFJ5pkpYmJB1WhMDw82vnnnnsucuzOO+/E9u3b8aUvfQnLly9HR0cHzp07h5GREfz+97/H8ePHsXnzZvzyl79EY2NjXG1vuOEG60ZP2Aa5Sbm5sw9PvNEFcaEluoqK7RMNaxI8ca4fbacvjhEU4v8WPds+RjBYvVpMxAo1FVfBiYalRrSzp5WqUHj//fcxNDSE+++/H6FQCD/4wQ8wMjKC6667DgBQXV2NI0eO4NNPP8X8+fMBADfeeCNOnjyJwcHBuNsqCQWnk4PPlx3fE7A5Tqcj7cfIYttbH0Ea6xQSRo8vm1uS8P7sbOuWnQSj4xV6B4axaf8HyMl2Y/GsIgDKq0W1d2v0/cdzTzvdA0jtb+CxhdPw+B9OIhCMUo1mOfDYwmmax5To8asKBY/Hg+9+97v4p3/6J5w9exYPPPAA8vLyIn/PycnB3/72NwwODiI3Nzdy3Ol0jjlmpK0S4bCQ9rVbM7k+7aUh+eCsS0OhMc8kEbrt8wopJ6IJBHk8/WYXaop9AJRXi2rv1uj7j+eedroHkNrfQE2xDw0Lysb8NmuKfZrHZLsazSUlJSguLgbHcSgpKYHX68WlS5cif/f7/cjLy0MgEIDf748c53keubm5MceMtCUSQyobDBOl21aKJZASvYpOhiE9EfdMtoNAqpBqnlaqcQovvfQSNm/eDADo6+vD0NAQsrOz8fHHH0MQBLS2tqKyshKzZ89GS0sLAOD48eMoLy9Hbm4usrKy4mpLWI9dU1Xne+TXLNLjLN12U3OXqWNgxRLIEa0zToRfvtQXHoDl98y0eINMgRMEQTEL18jICNasWYOenh5wHIfVq1fD4XBg06ZNCIfDqK6uxqOPPhrxKDp16hQEQcCmTZswdepUHD9+PK62SgSD4ZTdVmolEVtnOUMoMPqR71s+x9J7K9Hc2YcNb55CMPz5TzTLwWHtbeUxE0/V1hawfsQel8P0rK7RO6p5pRPwWscnY1bLZt1Ty/uX7pS09CGVdoaprD4yg0Srj1SFgp3JBKHQ0n3JcpdM1qTKATi6qsbUe+lFy/hZQk3EauFm5QSrZULQK9SNCJFkQkLBZjYFInk0d/Zh0/4PIp4LidaV28FtbvGsoojBloVaWmarfcKTrTPW6wtPrqSEEiQUbMwzh8/GuLIB1ny8djMYRq+8J+V78OC8YsXxin9rau6SLQspYHQ1Pa90gmw8gdVYrarRI9SbO/uYuyqtRnQivSGhYGMSFQ2pViAFSJwOWqra6OkPaNodiX9j7Rh6B4bHxhPo2HUZHX8iPKO0CnWxLywc9qnZQyQREgo2JpFqHSUVSCLTGaipNliTs3g8EOLh4NiF5FnXVSKe8SdCVaNFqLP6Eo34zFLJCE2YDwkFG7Ni/pQYmwKQHLVOInXQSrsjpTQT0R5Aeqpaatl1GRVUauMxEy12DbV7FnrdlM+IoHoKdqa2ogBP3jkj6X7giZjYRD971nzOccDWgx/JTs6vvNeruc6zFC27Li2CihXjYbQanBUo3VNcbCgJQCIzoJ2CzdHifWM1SmosM1QNci6SUngB6GfUJNZZ7z6C1l2X0vjVdhF2MuKzvLTyPS6s+tpU1FYUoJFRBa93YBiLnm0nlVIGQDsFQhW5SF6Py4F5pRNMiYRW03WrwTKQ5ntcMbusu2cVGtp1sca/Yv4U1V2UnaJ+5fryxO3T8KeVN0f6o7SbsFvEO2ENFLxmc+wSuCO3I5CrFSBSqGM1qRSRrIbH5cAdN1w7JqoYAO6eVYj6W8oNXjkW1o6IFTjm4ABBQNyr6kS/fy27NpFERbzb5RtIFhS8RtgSOUMmS9UA6DNQ6kk0F0202gNAjMspALzW8Qlm/UO+KatyliGXpZIRVVqpZqiV82RivRs7F4ohjENCgTCM2mSu1UNJbmLNcnAQBAEhhS3E+Cxn5Nptpy/K3n/rwY8sda+UTqKcjDtsqkULSwUgazdkh4h3wnzIpkAYRkvWUC2rSTld99rbyrGudhqK8j2ars26T38gZLkuvLaiAPuWz8HRVTVgKWNTeVWtZFOJRpqplWwOqQntFIgxyOnPAXZwlJJtgbWalLuHnH562dwSzP/pW6orVa0qKNaqPR4vquhzuau2BKW+mkkiAs20RrxTfEN6QEKBiEHu4258vSvGECz94GsrCrD5T6fG6PRZrpd6J5AV86fgieauGFWSi0PMtdWS4kUjXbXHM6FJz5UTCFa5oCZyIlYLjqMke+kDCQUiBrmPW04jIo3ofa3jkzFt7rjhWtkJwcgEwkmW4BwX64eqlhQvGumqndWfnx340HDqCLO8j5SwciLWuwNJVOQ2YT0kFIgY9HzEYlvWxChn/FW6h1Kq56Bkpg/ywpjJTyn4SkRu1c667+XhMC4PhwGwV+GscwXB+loUVk3ERnYgdk6/TuiDDM1EDHo+YrGt3slJb+oHPddX6j8rcEzrmOXSPSQzjYVV9zaS6kKrMZqwPyQUiBj01CEWP3i9k5PeCUTP9VnXfuL2adi3fA7TZqF1zFJBlMzJ0Kp7G9mB2Clym4gPUh8RMUg9TbxuJ4aC/Bj1zd2zCgGwfdiVJietqZ5F9OQP0ntt1jlDwbBsriVREG3+0ym88l4veGG0bOl4F4dASEhoXiAjY9WCUVVQsivQEeZAaS5sjh1C/FkuqixvHz0pLtQQx2/E9TIed02WN1XDrWU4ca5/zN8Ac9NqiCTj/duthrMdvoFkQmkuiJSAZVzO97gsyYejdxUar5upkjdVU7O8MfuV93pjhEKqFquxagdCpAYkFIgxRE9meR4X/MOhSIyAOLmy4gH6AyE0d/ZZuorXgl53TWkAmpxbq+hNxXJ5jT6e6sFcWoRwqgo9QhkSCkQM0slMTq+uVvJSzU9ebsJ8orkLWw9+hMuBUIyKamdbN873B1QnHekEpSeJm5YAtOhzWWOPTuGd7sFcqS70CDYkFIgYtNY2UAoQY3mpiBO33IQdiiqiIwoJjuMiBm6lSUdugmIhZyzVOmbx3G/MLJS1KXxjZmHkv9M9mCvdhV4mQy6pRAxaJ61Crxt5bqfs3+Qm3uiylVoICRjj8cTyldc6qbM8lrSMOfrc+lvKcfeswsjOwMGNNTLbqQynFaS70MtkNO0UPvvsMyxZsgS//vWv4XK5UF9fD47jUFZWhsbGRjgcDuzYsQOHDh2Cy+VCQ0MDZs6cie7u7rjbEolFS2K56AlSzr4glm6UJs2Lp7pa9LWlKE1EhVfH4+BihUr0apY15uhUFV/yudHU3IV1r3fBwY3uCtp/zI5YTnQZzkTr9ymCOX1xNjU1NSk1CAaDqKurw+XLl3HHHXdgy5YteOihh/CjH/0Ib731FsLhMAKBAF544QXs3r0b8+bNQ11dHZYuXYr6+vq42k6dOlWx8zwvIBAImvk8bIfHk2V4jM2dffjxKx34+aHT2HuyFxOys1B2Ta7iOROys3DkzBBOa9UAAB55SURBVEWEFPRDd365AP97TjHKrsnFpHw3OnsHMTgSjmkzOBLGWx98hhf+cg7XeMfhvzrMS6P8wl/OYcfhM5Exyd0f+Nw19siZi5Fdx+BIGEfOXMSkfHfkWciN2eNyYO1t5fjp4hvw8cUr+NOpzyI5oAQAnX2DuHBlGNWlX5DtY/Sz8Y+EUeh148dRBYG0ouX9i7uwS1fVb3JjNBvWM/vx16aafs94voF0wIrx5+SwhbfqUnzLli249957ce211wIAOjo6UFVVBQCoqanB22+/jXfffRfV1dXgOA5FRUUIh8O4cOFC3G0J40Sra/TUEoiOTGWx//1PY9rvWz6H2b4/EMK617vgdjIKKQPIczuRJSm07GI3R38gFDOmeaUTmJG9WlI2qEXjvvLeWPuBeFyphkB0nQVWNLUZsMa49eBHltwPoAjmdEZRfbRnzx5MnDgR8+fPx7PPPgsAEAQhkqEyJycHAwMDGBwchM/ni5wnHo+3rRpOJwefL1vnkFMLp9NhaIw727plJ4qdbd1YNrdE8dxlc0uwbG4Jyte+IZsh9fJwGC3dl7B4VlHkmJouORAWwCE246ony4En75yBxbOKsPdED7buP4Xz/QFMyvdg1YJyrHrpPZVRjo7pyNlLePKuGWPOXzyriJkgr29gOOa5imOWQ8kFddP+DxAIRnng7P8AOdnumGcTD1rev1KBIel7MhOlZ2YmRr+BdCHR41cUCi+//DI4jsORI0fQ2dmJuro6XLhwIfJ3v9+PvLw85Obmwu/3xxz3er0xNgEjbdUIh4W0j3Q0Gs14vj/APK71ekr2hSf+6/+hptinqa1I9Nya53Zi9devR02xD5cuXUFNsQ8136uK6MZXv/SeottrNOf7A5Hzo7l06Yqi7lvrc1DqhygQov/99JtdMc8mHrS8f6Vnb2ZfkkWiI5rtFn+R6IhmRfXR7373O/z2t7/Fc889h4qKCmzZsgU1NTVob28HALS0tKCyshKzZ89Ga2sreJ5HT08PeJ7HxIkTMX369LjaEsZhGfzyPC7NJROVjKLS+IUV86eMUQEpMRIeO8tKVV5aBAKgbNw0I2lctKupFhLtgTOvdALzb+QNpA+jatd0Qrd7T11dHbZv346lS5ciGAxi4cKFmDFjBiorK7F06VL84Ac/wLp160xpSxhHbjLMcnDwD2uvWaxndVRbUYDxWdp/TnLupUY8lNQmeDN037P+IX/Mh+IAdLnkWgUrJUcy+pIOGEkbnm5QQjybE8/WUboNvjISihSNiabQ647kK5Kec+nKCAIyq3pgNDto9Pa6amuLrA2CBYfYQjR6z8/3uLDKgEePXliZYPM9LgyHeEsTx6m9f1bfrOhLskik+oj1G5T+VhMJJcSzMVbpGq26bnT+mubOPqxTMLqKbaSRwUoqoejdBqDNrhCNV7LS1nP+E7dPS9hkx6zMFghh/e3Tkqp/VlIPpYNASDQUf0FCQTNW5XpJRA4Z8R4sxB+83NY5yI/1GpIibq/lAraUkNZZ1np+oded0MlOaaJIdg0BVt+0PiO7GVWTTaKDDu0IhQxrxCpdYyJ0mEq6+ugfPGuVrkWl0zswjGcOn8UdN1yrGOMQzWWJsVqq/89zO5ElE99wZSRkyPCnFFOg1HYoGB4TN2GXiSIeQzoZVcdC8Re0U9CMVbleEpFDRouKQWki0Ooa2jswjNc6PkHDrWXMxHfRFHjdsivV6HoMLd2X8MR//b8Yb6fLw2HF5HhyK189OzK5TLFZDg554xwYGA7bakUdT+0DSmonT7J3f8mGhIJGrNI1Wq3DbO7sY670o1UMSjuTb8wsxGsdn2hSC2lVJXlcDswrnaA4UTd39mFnWzczfbd08lKa+PVMgCw12hfGuXDg4XmqzyDRGJ3EKKkdIQepjzRiVZF0Kwu/N3f24QlGlTAXFxuHoDQR1N9SjoZbyzTft29gWFYVlO9xxWzJ205fZE7U4gTfwwjCk+uz0sSvZwLMlMky3TO5EsagnYJGrCpRaGXpw2cOn41UTJOS43ZpyhQq2gdqKwo0qYTEa2kxYCqloNASsyCdvJQmcz07skzxQCGjKiEHCQUdmKlrTITXh9LKtj8QiklvrWWC0Ood1DcwHOP+ytLfK02+aqtyuclL6Xp6JsBMmSypFjMhh2rqbDuTqqmz9aQ6jidt7t6TvbIppUWi71tbUaCa6llMB/3nDz/TFWQGACFeQGfvIO67aXLkmFL6ZVY6bADMNNRK19MyPuk44017bQZWp40uuyYX9900GQ/cXIz7bppsWarteKDU2YlNnU0RzUmAFYUaHVks4vNl4/8cOaNrNadU9lIO6X3VdjF6I49F5KJCtXoLAaN2kBy3K6aOs1bvo1Ql0cng7EimPwOKaM4A9Bgy957o0edK+eYpZloKLf3R4rqpN3JZRE4nz1LJicd2tnXjfH8AXrcTQ0E+po6z3HOQu166CQqCsBISCklAjyFz6/5TigVUxMnO63ZicDgMIwUv8zyf/wy0uG7qjVwGjOnkaysKsGxuCS5duoJFz7bj8nDsM9PiU5+IiHGCSCfIJTUJ6HFDZdVF6A+EsOGNU5Fo1MsGBQIwWjhJhLWLEesuN3f2jXE3VcuOmud2RlxatUYUSzHqJkpZLwlCH7RTMBGtago9Xh+T8j1MX/2g1oIDKgxEZU5VUg1JV9lifxc9246hoHzh+6baabojiuUw6iaqNJZMgdRnhB5op2ASevPIiG6govulGLAlZdWCcot7Hjuxyu1iopFbZbNW64IQKwDjWbEbDfJjJXkVj+vJh5SKUH4jQi+0UzCIXK0CPXlktK6cF88qwvp9HbJ1EMyid2AYc7a1gBdGPZHuuOFatJ2+yFxNS4WAllV8vFHCRn3qleorZ4K9gfIbEXohoWAAucmEhaiLl05kej7W1V+/XtY9k+M401RI4mW0JLWTqmy0BHuZESVsJHiwUCFSOxMmTCUbUTSkYiJESH2kk+bOPjQ1d+nyvJHbuutZOYuG3ejyjzluFxZ/uUBzmmo9RCe106Ky0ZJu2MocT0oo3TcTchxFe5ZJEVVIpGIioqGdgg7Ejyeexbk44RpZOUcXu+8PhCIretGQqydgTY3egWE0vt4Fr9sJt0s5YAxQX8UnK6WC0n217oRSGaXYVHFHlAk7JkI7JBR0oJakLd/jwvgsp2ICNmB0Jbr+9mmKKhe9Ngvxf0o1e7XWRRARXV09LgfWGyx/aQe1BEtgpXOOI/G5K9mixB1RJuyYCO2QUNCB0kficTliisiLaia5SVgs4wjIr2CN2izyPC7Z2gPAaIqJptqxgkgLRleNdjfkpktCOKngnVc6QVP9C3FHlClZYQltkFDQAevjcXCxRdKV1EzRK1HWClZL2uhoxD6xBILYd+kkqEcLZmTVmApqiVSvsiUneF8+0at6XnQ9DVaEulj2NJWfD6EfEgo6YKkbpEZV1qQuFR4szN62swRRc2cfNrxxSpMHk5FVoxa1hBXqJTuorBKF3gUEMBphvvrr10eeifj/Ww9+pLnsKZG+kFDQgVZ1g5ZgLhG5CUxLwjmWq6UcbpcDja93RTyKpJOBeH9OweZgRM+uppawQr1kd5WV2ehZQMhl4RURDc7S3abddnaE9ZBQ0ImWLJxet1PWwCddbbMmsC9PylWd8HsHhjUbjqMzi657vQvrXu9CvscVsYFI1V7SlefdswoNTQpKhlyWzSXeSYilsmq6WpY03SY3rRlrtRjQyeBMACQUNKM173/vwDCyHBxcHGJKYcp9lFsPfiQ7gR3722VNfYrHNVZMqAeAuXOIV/UinvezAx9GhKTb5cCJc/14reMTZv/jmYRY5/IC0nLHsGL+lJgqd9E4uNHdqdb3SAZnAtAQvBYOh7FmzRrce++9+Na3voWPP/4Y3d3dWLZsGe677z40NjaC50cnth07duCee+7Bvffei/feew8ATGmbbJSCe+RWpkFeQI7bpRjMtflPpxQNw4kgyAsxuYes0sVL4ytePtGrqAePZxJSOjcds6MqvR9BGC1qtGL+FDxz+KxqfqdkBRgS9kJVKLz11lsAgOeffx4//OEP8dRTT+Gpp57CI488gt27d0MQBBw4cAAdHR04evQoXnzxRWzbtg3r168HgLjb2gElLxrWyvRyIMRMeNfc2afJQyQRiP23KqpVryE03klILaFfOqpCWFHtBV63rveqJTKdSH9U1Ue33HILvvrVrwIAenp68MUvfhGHDh1CVVUVAKCmpgZtbW0oKSlBdXU1OI5DUVERwuEwLly4gI6OjrjaLliwgNk3p5ODz5cd7zNQRSl/jJMD5Aqd+bKzsGn/BwgEo+wF+z9ATrYbO9u6reyuLnzZWbjzV0dl03MHQjx2tnVj2dwSw9fXMwk7OeDJu2Zg8ayiz485Hbre8bK5JXj/71ew++jfZP8+Kd8Tc729J3qwdf8pnO8PYFK+B6sWlMfc3whmXlPL+B9bOA2P/+Fk5LcGAJ4sBx5bOI1ZpIn1XpfNLYnrfVuB3t9AupHo8WuyKbhcLtTV1WH//v34xS9+gbfeegscN5p7OCcnBwMDAxgcHITP54ucIx4XBCGutkqEw0JCarcqGfNYlS8vXhlbaDsQ5PH0m12mrlY9LgfcLodhVdTFK0FcBLsoeE9/wNAzFlVRWs0eomtvTbEv5n5G6tMe7PyE+bcH5xVHrrf5T6didmw9/QE8/upJ+K8Mm+b9FO81tYy/ptiHhgVlY1R/NcU+rGbU4jhv8L0mA6rRbNMazVu2bMHq1avxzW9+E8NRZRH9fj/y8vKQm5sLv98fc9zr9cLhcMTV1g5oKT+p1RNILQWGHgqvfvwAVPvn4oAsJ4ehkH7rtDSASc32wPJiUuKOG641TU2hJHSjPa3kVHhWeT9Z7dbJCsIj4zGhF1Wbwquvvopdu3YBAMaPHw+O4zBjxgy0t7cDAFpaWlBZWYnZs2ejtbUVPM+jp6cHPM9j4sSJmD59elxt7UC0rpWFIIzmPlLD63ZixfwpyGJVf9GI6HMuTgZSXfDdswpj/r2udhpafjQfx1bV6M6sKjVGq+molewIrGG3nb6oq09KsCa86HErGZyt8H5Kli2DjMeEXlRnsVtvvRVr1qzBt771LYRCITQ0NGDq1KlYu3Yttm3bhtLSUixcuBBOpxOVlZVYunQpeJ7HunXrAAB1dXVxtU02zZ19MZGeHCCrEtG6+h+6qvcdn+VAMI7COdIUBErpGsSVvZj1VG/BnugJTctKmDUBchgVnmr3iBctie6U7hev95PRlbncDixe/X665HciEgcnKOXWtTnBYNhSXaPWNBCiPpzlLy6l8KpHUrwP3sUB62qVs5dK9eZGiI6ErdraIttvDqPujwCYmVrFlTrrb3LRtkb1qWoqLqVssk8YzAgr3ldLKhSt5z151wzUFPuY52UCZFOwqU0hE3nm8FmmQJALDIoO0lJCjEaOVxyHhNHAsGg9uTRbph6BMD7LgWCIVwy6Y62E8zyuSLZWr9s5xisry8Ex7R9WqDPUEt2x7ER6oreVBI/elTlrB7Z1/ynUfK9KU38IwgxIKCigpGIQA4OiWf316/FEcxe02HJNqqIZEUJGs2WKiKtjtRW23GSa5eDgHw5FVGxyglHckNpFnaG1H3oi2aMjpvWOh/VbO8/wHiIIqyChoICSnUBORyxOBKw6CkZg2TCkGMmWKVIYlVbbSAW1KyMh1R1SSPi80pdd0lWr9UNp4jfby4j1W5uU79F9LYKIB6rRrADLSyg6F72U2oqCuNVC0Wi5lJJ+XA0tqpvmzj4serY9kiYBAPYtn4Ojq2qwb/kcDGg0XKdaNLGRSHajY2R5Ca1aUK56rvT9UG1lIh5op6CAXJ55aS56OZSK8Zi1g4hGr0AYn+VAIMhrUt1oSUWt1fMq1XzjlSZ+s/3/WeqsxbOKFI2MmZYqnLAeEgoqGFF1sIyYVggEvYzPciDfk4VAUJsg0aIm0RLcZ7YxORGFdJQmfivqOxv5raVCdTsitSChYAF6itcUXvUSajt9UVeNBBaiu6vX7cRQkI/xnspycAiG+MhEp2VVqUVNIrfKFcdkxaSdqNWx0sSfDIO5nCC0W7AckfqQULAA6cfLUq1wwBjffLUUEQ4OyB0nH4Am9fWX9kPOIKy2qtSqJkmk8ThRq2O1iV/6dzFK2ornICcI173ehfFZjkhAZDSppqoj7AMJBYPocVVk4XU7xxxT8iISg6AAdV9/uf41MoLregeGIzEG0onPCjWJVpo7+7CzrRvn+wMx/Urk6lhamU6MDBd3Q691fJIQfT7rdzEU5Ed3gFE7QkpjQcQDCQUD6HVVZDEU5Mckm1Oa2KRRsawVLKt/SikuWColq9QkepPqRfcrGUnetMaBWKXPV/pdjM9y4AvjXJTGgjAFEgoStBgwjbgqyiFWPou+PmvCi44lAJTVNaz+uV0ueFwOVaElndjMVg1psQkoPeNk7F70CHsrdixKasiB4TAOPDzP9HsSmQnFKUShtUqVkvpCTiWkRO/AcMz1zchqqVQNTppNVe81zEBpwle7f9/AcFIqhOl5HlbsWJTeP9kPCDOhnUIUrMmqqbkrokdeMX8K8jwu2aI2BV43hoL6M58qqWsm5Xvw4LxiXROeknpFuupnBb5ZOdFosQmoqYgSHRWtNRbDqh1LbUUBTpzrH6OyIvsBYTa0U4iCNVnxAiI7hw1vnMJlGYEgJnyT+5sa0lVybUVBJGL4z6u/aihOQutuIxn59lkCJ/q43eoAsPojrVth5Y6l/pZyPHH7NKqhbCIUDT4W2ilEwdoBRMPKmhq6etxoVTUz1TVajMPRthOv2wm3y4XLgVBCDJVabALi/eW8j5JBMhP5JSJQLxOhaHB5qJ7CVZo7+zRnOGXhcTlwxw3XxrgpAqO5kjiOU6zLYHY9ASWM5vw3uw9aJrpMz6Xf0n0Jj796MqnvKtlY9RtQqvsh9y0mC6qnkCSeOXw2LoEAjKqB2k5fRMOtY4uoA8rZUxOpFrFDagS7ZEq1O1v3n0r6u0pXKBpcnowUCnrSBUjJcnAQBIEpQETvGDlVjVL6CtYHvvdED55+s8uQ6oC1GqePIXVg1VOgdxU/yYh3SQUyTigYCewScXDA2ttGUxmzVv3SH5Ra2gqA7Rra3NmHTfs/QCCoX+dpt+CvTMAK3f+kfA96ZAQDvav4SWa0vp3JOO8jluqE47gx3iVSBOFztUdT7bQxtRaiS04q3S8apR/hM4fPRgRCdF+jPZVYqAV/2cmzJx3QGuOil1ULyuldWUQy4l1SgYzbKSgFdq2/fRqeOXyWncCOQ0xaCqmNXs5mr7TNL1QpAcnqh5rqoLmzT/Fcu5TETCesstMsnlUE/5VhelcWQbatsWScUNAS2MVS+fACYnIcSe0K0SUn1e7H8nDQom5SUh2I56uda6ePIR1cLq2009jpXRHpT8apj7SoTsRtpUwlTgRCPNa93qV5Fa9XVROPukntfDuqHaxSu2i9t1mBS1oC8ggiFcg4oaBVj2i01rLX7RxTz1iP3lJN3aSm89STZdUOaMmDZAVmCyOy0xDpQsapjwDt23G90ckubjQd9uXh2DTUDbeWaQ6G0atu0nO+3QQCkDxfcbNtAGSnIdIFRaEQDAbR0NCAc+fOYWRkBA899BCuv/561NfXg+M4lJWVobGxEQ6HAzt27MChQ4fgcrnQ0NCAmTNnoru7O+62yWRe6QTZnPlSOHyeDE+aJkPvRBOvm5yW883U4cd7rWS5x1ohjEj3T6QDirPu3r174fP5sHv3bvz7v/87NmzYgKeeegqPPPIIdu/eDUEQcODAAXR0dODo0aN48cUXsW3bNqxfvx4A4m6bbNpOX1RtU+h14+iqGuxbPoeZDE/PRCNVbxXle3SpfdTUY2aqTcy4VrLULmQDIAh5FHcKt912GxYuXBj5t9PpREdHB6qqqgAANTU1aGtrQ0lJCaqrq8FxHIqKihAOh3HhwoW42y5YsMCqcWtCbTKXTl5mrXqjV5xG8p4YKcBjRG1ixrWSpXahwCWCkEdRKOTk5AAABgcH8cMf/hCPPPIItmzZAo7jIn8fGBjA4OAgfD5fzHkDAwMQBCGutmo4nRx8vmydQ9YOK5oUGF3Br1pQjsWziiLHHls4DY//4WRMwJkny4HHFk4z3E+n02HqGJXUJnrvY9a1ls0twbK5JbJ/M3v80ffMyXZj6/5TON8fwCSZ92kHrBp/KpHpzyDR41c1NJ8/fx4rV67Efffdh0WLFuHpp5+O/M3v9yMvLw+5ubnw+/0xx71eb4xNwEhbNcJhwdIMmg/OK1bNJhp9/5piHxoWjE2GV1PsM9xPszMkKu1m9N7HzGuxsDJLak2xDzXfq4o5ZreMrJmeJRagZ5DoLKmKNoW///3vuP/++/HYY4/hnnvuAQBMnz4d7e2jrpYtLS2orKzE7Nmz0draCp7n0dPTA57nMXHixLjbJhsjYfDRBXL2LZ9jO8OjmTp8csMkiPRDsZ7Cxo0b0dzcjNLS0sixxx9/HBs3bkQwGERpaSk2btwIp9OJ7du3o6WlBTzPY82aNaisrMSZM2ewdu3auNoqYWY9BbtiVT0Fu3gfqUGrxMweP0DPINE7BSqyY3Pog6DxZ/L4AXoGtlIfEQRBEJkFCQWCIAgiAgkFgiAIIgIJBYIgCCICCQWCIAgiQkp7HxEEQRDmQjsFgiAIIgIJBYIgCCICCQWCIAgiAgkFgiAIIgIJBYIgCCICCQWCIAgiAgkFgiAIIoJqkR0iPsLhMH7yk5/gzJkzcDqdeOqppyAIAurr68FxHMrKytDY2AiHw4EdO3bg0KFDcLlcaGhowMyZM9Hd3R13Wzvw2WefYcmSJfj1r38Nl8uVUeO/66674PWOZqWcPHkyli5diieffBJOpxPV1dV4+OGHwfM8mpqa0NXVhXHjxmHjxo0oLi7G8ePH42prB3bt2oWDBw8iGAxi2bJlqKqqyqj3v2fPHrzyyisAgOHhYXR2duK5556z729AICxl//79Qn19vSAIgvDOO+8IDz74oPD9739feOeddwRBEIS1a9cKf/zjH4WTJ08K3/72twWe54Vz584JS5YsEQRBiLutHRgZGRFWrFgh3HrrrcKHH36YUeMPBALCnXfeGXNs8eLFQnd3t8DzvPC9731POHnypPDmm28KdXV1giAIwl/+8hfhwQcfNKVtsnnnnXeE73//+0I4HBYGBweFX/ziFxn1/qU0NTUJzz//vK1/A8kXo2nOLbfcgg0bNgAAenp68MUvfhEdHR2oqhotA1lTU4O3334b7777Lqqrq8FxHIqKihAOh3HhwoW429qBLVu24N5778W1114LABk1/vfffx9DQ0O4//778Z3vfAfHjh3DyMgIrrvuOnAch+rqahw5cgTvvvsu5s+fDwC48cYbcfLkSQwODsbdNtm0traivLwcK1euxIMPPoivfvWrGfX+o/nrX/+KDz/8EHfccYetfwMkFBKAy+VCXV0dNmzYgIULF0IQBHAcBwDIycnBwMAABgcHkZubGzlHPB5v22SzZ88eTJw4MfIDBpBR4/d4PPjud7+L//iP/8D69euxZs0ajB8/PvJ31picTidznHraJpuLFy/i5MmT+Ld/+zesX78eq1evzqj3H82uXbuwcuVKU96rlb8BsikkiC1btmD16tX45je/ieHhz4vd+/1+5OXlITc3F36/P+a41+uN0YkaaZtsXn75ZXAchyNHjqCzsxN1dXW4cOFC5O/pPv6SkhIUFxeD4ziUlJTA6/Xi0qVLkb+L/QwEAjFj4nledpx62yYbn8+H0tJSjBs3DqWlpXC73ejt7Y38Pd3fv8jly5dx+vRpfOUrX8Hg4GDc79XK3wDtFCzm1Vdfxa5duwAA48ePB8dxmDFjBtrb2wEALS0tqKysxOzZs9Ha2gqe59HT0wOe5zFx4kRMnz49rrbJ5ne/+x1++9vf4rnnnkNFRQW2bNmCmpqajBn/Sy+9hM2bNwMA+vr6MDQ0hOzsbHz88ccQBAGtra2RMbW0tAAAjh8/jvLycuTm5iIrKyuutsnmpptuwuHDhyEIQmT8c+fOzZj3L3Ls2DHcfPPNAGDKe7XyN0BZUi3mypUrWLNmDf7+978jFArhgQcewNSpU7F27VoEg0GUlpZi48aNcDqd2L59O1paWsDzPNasWYPKykqcOXMm7rZ24dvf/jaamprgcDgyZvwjIyNYs2YNenp6wHEcVq9eDYfDgU2bNiEcDqO6uhqPPvpoxJvk1KlTEAQBmzZtwtSpU3H8+PG42tqBn/70p2hvb4cgCHj00UcxefLkjHn/Ir/61a/gcrnwL//yLwAQ93u18jdAQoEgCIKIQOojgiAIIgIJBYIgCCICCQWCIAgiAgkFgiAIIgIJBYIgCCICCQWCIAgiAgkFgiAIIsL/B3oNEgLBVTp2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predrf = fitted_models['rf'].predict(X_test)\n",
    "\n",
    "plt.scatter(predrf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<img src=\"data:image/png;base64,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&#10;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.7 - Saving Your Model</span>\n",
    "\n",
    "Great job, you've created a pretty kick-ass model for real-estate valuation. Now it's time to save your hard work.\n",
    "\n",
    "#### A.) First, display the class of your winning \"model\" in the <code>fitted_models</code> dictionary object.\n",
    "* Remember, you can access it with its corresponding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score=nan,\n",
      "             estimator=Pipeline(memory=None,\n",
      "                                steps=[('standardscaler',\n",
      "                                        StandardScaler(copy=True,\n",
      "                                                       with_mean=True,\n",
      "                                                       with_std=True)),\n",
      "                                       ('randomforestregressor',\n",
      "                                        RandomForestRegressor(bootstrap=True,\n",
      "                                                              ccp_alpha=0.0,\n",
      "                                                              criterion='mse',\n",
      "                                                              max_depth=None,\n",
      "                                                              max_features='auto',\n",
      "                                                              max_leaf_nodes=None,\n",
      "                                                              max_samples=None,\n",
      "                                                              min_impurity_decrease=0.0,\n",
      "                                                              min_impurity_...\n",
      "                                                              min_weight_fraction_leaf=0.0,\n",
      "                                                              n_estimators=100,\n",
      "                                                              n_jobs=None,\n",
      "                                                              oob_score=False,\n",
      "                                                              random_state=1234,\n",
      "                                                              verbose=0,\n",
      "                                                              warm_start=False))],\n",
      "                                verbose=False),\n",
      "             iid='deprecated', n_jobs=-1,\n",
      "             param_grid={'randomforestregressor__max_features': ['auto', 'sqrt',\n",
      "                                                                 0.33],\n",
      "                         'randomforestregressor__n_estimators': [100, 200]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print(fitted_models['rf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.model_selection._search.GridSearchCV\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is still the <code style=\"color:steelblue\">GridSearchCV</code> class. \n",
    "* You can actually directly save this object if you want, because it will use the winning model pipeline by default. \n",
    "* However, what we really care about is the actual winning model <code style=\"color:steelblue\">Pipeline</code>, right?\n",
    "\n",
    "#### B.) Confirm you can access the winning model pipeline. Display the class of the model pipeline.\n",
    "* **Tip:** You can use its <code style=\"color:steelblue\">best\\_estimator_</code> method to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'].best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.pipeline.Pipeline\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Display the winning pipeline object directly. What are the values of the winning values for our hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
      "                                       criterion='mse', max_depth=None,\n",
      "                                       max_features=0.33, max_leaf_nodes=None,\n",
      "                                       max_samples=None,\n",
      "                                       min_impurity_decrease=0.0,\n",
      "                                       min_impurity_split=None,\n",
      "                                       min_samples_leaf=1, min_samples_split=2,\n",
      "                                       min_weight_fraction_leaf=0.0,\n",
      "                                       n_estimators=200, n_jobs=None,\n",
      "                                       oob_score=False, random_state=1234,\n",
      "                                       verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(fitted_models['rf'].best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning values for our hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's save the winning <code style=\"color:steelblue\">Pipeline</code> object object. To do so, we'll import a helpful package called <code style=\"color:steelblue\">pickle</code>, which saves Python objects to disk.\n",
    "* First, <code>import pickle</code>.\n",
    "* Then, use the following syntax to \"dump\" your model into a pickle file.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(<strong>insert answer to previous question here</strong>, f)\n",
    "</pre>\n",
    "* **Note:** We'll show you in the next project how to take this a step further and use the pickled model for various use cases. For now, we don't want to spread ourselves too thin over too many topics, so let's just save that final model and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('final_mode.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations... you've built and saved a successful model trained using machine learning!\n",
    "\n",
    "As a reminder, here are a few things you did in this module:\n",
    "* You split your dataset into separate training and test sets.\n",
    "* You set up preprocessing pipelines.\n",
    "* You tuned your models using cross-validation.\n",
    "* And you evaluated your models, selecting and saving the winner."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
